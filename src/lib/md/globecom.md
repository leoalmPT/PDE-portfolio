I contributed to the paper "From Black Box to Transparency: Consistency and Cost within XAI" which was been accepted for presentation at GLOBECOM 2024. This paper was developed at Instituto de Telecomunicações and the main author is my colleague, Julio Corona.

<br>

This paper explores the role of Explainable AI (XAI) in enhancing the transparency of Machine Learning (ML) models used in 5G and future 6G networks. It evaluates three XAI methods—SHAP, LIME, and Permutation Importance (PI)—by comparing their consistency in determining feature importance across multiple ML models in distinct 5G scenarios. Additionally, the paper analyzes the temporal and energy costs of each technique. The results show that while PI is the most cost-efficient, inconsistencies in feature relevance across methods suggest that using multiple XAI techniques is essential for reliable model explanations.

<br>

In this collaborative effort, I contributed to the analysis of different XAI techniques, focusing on the consistency of feature importance across various methods,
